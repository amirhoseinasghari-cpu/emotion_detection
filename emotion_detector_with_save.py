import cv2
import numpy as np
import os
import time
import json
from datetime import datetime

class EmotionDetector:
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
        self.cap = cv2.VideoCapture(0)
        self.emotions = {
            0: {"name": "ğŸ˜  Ø¹ØµØ¨Ø§Ù†ÛŒ", "color": (0, 0, 255)},
            1: {"name": "ğŸ˜„ Ø´Ø§Ø¯", "color": (0, 255, 0)},
            2: {"name": "ğŸ˜¢ ØºÙ…Ú¯ÛŒÙ†", "color": (255, 0, 0)},
            3: {"name": "ğŸ˜² Ù…ØªØ¹Ø¬Ø¨", "color": (0, 255, 255)},
            4: {"name": "ğŸ˜ Ø®Ù†Ø«ÛŒ", "color": (255, 255, 0)}
        }
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ
        self.setup_folders()
        
        # Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡
        self.collected_data = []
        self.photo_count = 0
    
    def setup_folders(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù… Ø¨Ø±Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ"""
        folders = ['saved_faces', 'data_logs']
        for folder in folders:
            if not os.path.exists(folder):
                os.makedirs(folder)
                print(f"âœ… Ù¾ÙˆØ´Ù‡ {folder}/ Ø§ÛŒØ¬Ø§Ø¯ Ø´Ø¯")
    
    def save_face_data(self, face_roi, emotion_id, confidence):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³ Ú†Ù‡Ø±Ù‡ Ùˆ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…Ø±Ø¨ÙˆØ·Ù‡"""
        try:
            # ØªÙˆÙ„ÛŒØ¯ Ù†Ø§Ù… ÙØ§ÛŒÙ„
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"saved_faces/face_{timestamp}_{emotion_id}_{self.photo_count}.jpg"
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³
            cv2.imwrite(filename, face_roi)
            
            # Ø°Ø®ÛŒØ±Ù‡ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ù…ØªØ§
            face_data = {
                "filename": filename,
                "emotion_id": emotion_id,
                "emotion_name": self.emotions[emotion_id]["name"],
                "confidence": float(confidence),
                "timestamp": datetime.now().isoformat(),
                "face_size": f"{face_roi.shape[1]}x{face_roi.shape[0]}"
            }
            
            self.collected_data.append(face_data)
            self.photo_count += 1
            
            print(f"ğŸ“¸ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
            return True
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ: {e}")
            return False
    
    def save_data_log(self):
        """Ø°Ø®ÛŒØ±Ù‡ Ú©Ù„ÛŒÙ‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø¯Ø± ÙØ§ÛŒÙ„ JSON"""
        if not self.collected_data:
            return
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"data_logs/emotion_data_{timestamp}.json"
        
        try:
            with open(log_filename, 'w', encoding='utf-8') as f:
                json.dump(self.collected_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ“Š Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {log_filename}")
            print(f"ğŸ“ˆ ØªØ¹Ø¯Ø§Ø¯ Ø±Ú©ÙˆØ±Ø¯Ù‡Ø§: {len(self.collected_data)}")
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ù„Ø§Ú¯: {e}")
    
    def show_statistics(self):
        """Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡"""
        if not self.collected_data:
            print("ğŸ“­ Ù‡ÛŒÚ† Ø¯Ø§Ø¯Ù‡â€ŒØ§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ù†Ø´Ø¯Ù‡ Ø§Ø³Øª")
            return
        
        emotion_counts = {}
        total_confidences = {}
        
        for data in self.collected_data:
            emotion_name = data["emotion_name"]
            if emotion_name not in emotion_counts:
                emotion_counts[emotion_name] = 0
                total_confidences[emotion_name] = 0
            emotion_counts[emotion_name] += 1
            total_confidences[emotion_name] += data["confidence"]
        
        print("\nğŸ“Š Ø¢Ù…Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù…Ø¹â€ŒØ¢ÙˆØ±ÛŒ Ø´Ø¯Ù‡:")
        print("=" * 40)
        for emotion, count in emotion_counts.items():
            avg_confidence = total_confidences[emotion] / count
            print(f"{emotion}: {count} Ù†Ù…ÙˆÙ†Ù‡ (Ù…ÛŒØ§Ù†Ú¯ÛŒÙ† Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {avg_confidence:.1%})")
    
    def analyze_face_features(self, face_roi):
        """Ø¢Ù†Ø§Ù„ÛŒØ² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú†Ù‡Ø±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        try:
            gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
            height, width = gray.shape
            
            top_half = gray[0:height//2, :]
            bottom_half = gray[height//2:, :]
            
            brightness = np.mean(gray)
            contrast = np.std(gray)
            top_bottom_ratio = np.mean(top_half) / max(np.mean(bottom_half), 1)
            
            if brightness > 170 and contrast > 60:
                return 1, 0.85  # Ø´Ø§Ø¯
            elif brightness < 100:
                return 2, 0.75  # ØºÙ…Ú¯ÛŒÙ†
            elif top_bottom_ratio > 1.3:
                return 3, 0.80  # Ù…ØªØ¹Ø¬Ø¨
            elif contrast < 40:
                return 4, 0.70  # Ø®Ù†Ø«ÛŒ
            else:
                return 0, 0.65  # Ø¹ØµØ¨Ø§Ù†ÛŒ
                
        except Exception as e:
            return 4, 0.5
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ"""
        if self.face_cascade.empty() or not self.cap.isOpened():
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…")
            return
        
        print("ğŸ­ Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø¯Ø§Ø¯Ù‡")
        print("=" * 50)
        print("âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")
        print("\nğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§:")
        print("- A: Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± Ø¹Ú©Ø³â€ŒÙ‡Ø§ (Ù‡Ø± 3 Ø«Ø§Ù†ÛŒÙ‡)")
        print("- S: Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø³ØªÛŒ Ø¹Ú©Ø³ ÙØ¹Ù„ÛŒ")
        print("- D: Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§")
        print("- Q: Ø®Ø±ÙˆØ¬ Ùˆ Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ")
        
        start_time = time.time()
        detection_history = []
        auto_save = False
        last_auto_save = time.time()
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(100, 100))
            
            current_emotion = None
            
            for (x, y, w, h) in faces:
                face_roi = frame[y:y+h, x:x+w]
                emotion_id, confidence = self.analyze_face_features(face_roi)
                emotion_data = self.emotions[emotion_id]
                current_emotion = emotion_id
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
                detection_history.append(emotion_id)
                if len(detection_history) > 20:
                    detection_history.pop(0)
                
                # Ø±Ø³Ù… Ù…Ø³ØªØ·ÛŒÙ„ Ø¨Ø§ Ø±Ù†Ú¯ Ø§Ø­Ø³Ø§Ø³
                cv2.rectangle(frame, (x, y), (x+w, y+h), emotion_data["color"], 3)
                
                # Ù†Ù…Ø§ÛŒØ´ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                emotion_text = f"{emotion_data['name']} ({confidence:.0%})"
                cv2.putText(frame, emotion_text, (x, y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, emotion_data["color"], 2)
                
                # Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
                if auto_save and time.time() - last_auto_save > 3:
                    self.save_face_data(face_roi, emotion_id, confidence)
                    last_auto_save = time.time()
            
            # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
            runtime = int(time.time() - start_time)
            stats_text = f"Ú†Ù‡Ø±Ù‡â€ŒÙ‡Ø§: {len(faces)} | Ø²Ù…Ø§Ù†: {runtime}s | Ø¹Ú©Ø³â€ŒÙ‡Ø§: {self.photo_count}"
            cv2.putText(frame, stats_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # ÙˆØ¶Ø¹ÛŒØª Ø°Ø®ÛŒØ±Ù‡â€ŒØ³Ø§Ø²ÛŒ Ø®ÙˆØ¯Ú©Ø§Ø±
            auto_status = "Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø±: ÙØ¹Ø§Ù„" if auto_save else "Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø±: ØºÛŒØ±ÙØ¹Ø§Ù„"
            cv2.putText(frame, auto_status, (10, 60), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if auto_save else (0, 0, 255), 2)
            
            # Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§
            help_text = "A:Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± S:Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø³ØªÛŒ D:Ø¢Ù…Ø§Ø± Q:Ø®Ø±ÙˆØ¬"
            cv2.putText(frame, help_text, (10, frame.shape[0]-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
            
            cv2.imshow("ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª - Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡", frame)
            
            # Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒØ¯Ù‡Ø§
            key = cv2.waitKey(1) & 0xFF
            if key in [ord('q'), ord('Q')]:
                break
            elif key == ord('a') or key == ord('A'):
                auto_save = not auto_save
                status = "ÙØ¹Ø§Ù„" if auto_save else "ØºÛŒØ±ÙØ¹Ø§Ù„"
                print(f"ğŸ”§ Ø°Ø®ÛŒØ±Ù‡ Ø®ÙˆØ¯Ú©Ø§Ø± {status} Ø´Ø¯")
            elif key == ord('s') or key == ord('S'):
                if faces and current_emotion is not None:
                    face_roi = frame[y:y+h, x:x+w]
                    emotion_id, confidence = self.analyze_face_features(face_roi)
                    self.save_face_data(face_roi, emotion_id, confidence)
            elif key == ord('d') or key == ord('D'):
                self.show_statistics()
        
        # Ø°Ø®ÛŒØ±Ù‡ Ù†Ù‡Ø§ÛŒÛŒ Ùˆ ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù†
        self.save_data_log()
        self.show_statistics()
        self.cap.release()
        cv2.destroyAllWindows()
        
        runtime = int(time.time() - start_time)
        print(f"\nâœ… Ø¨Ø±Ù†Ø§Ù…Ù‡ Ù¾Ø§ÛŒØ§Ù† ÛŒØ§ÙØª!")
        print(f"â±ï¸  Ù…Ø¯Øª Ø§Ø¬Ø±Ø§: {runtime} Ø«Ø§Ù†ÛŒÙ‡")
        print(f"ğŸ“¸ ØªØ¹Ø¯Ø§Ø¯ Ø¹Ú©Ø³â€ŒÙ‡Ø§ÛŒ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯Ù‡: {self.photo_count}")

if __name__ == "__main__":
    detector = EmotionDetector()
    detector.run()
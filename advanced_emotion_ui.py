import cv2
import numpy as np
import os
import time
import json
import pickle
from datetime import datetime
import matplotlib.pyplot as plt
from matplotlib.backends.backend_agg import FigureCanvasAgg
import warnings
warnings.filterwarnings('ignore')

class AdvancedEmotionUI:
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
        self.cap = cv2.VideoCapture(0)
        
        # Ù…Ø¯Ù„ Ùˆ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§
        self.model = None
        self.is_trained = False
        self.training_data = []
        self.training_labels = []
        
        # Ø¢Ù…Ø§Ø± Ùˆ ØªØ§Ø±ÛŒØ®Ú†Ù‡
        self.emotion_history = []
        self.session_start_time = time.time()
        self.faces_detected = 0
        self.predictions_made = 0
        
        # Ø§Ø­Ø³Ø§Ø³Ø§Øª
        self.emotions = {
            0: {"name": "ğŸ˜  Ø¹ØµØ¨Ø§Ù†ÛŒ", "color": (0, 0, 255), "count": 0},
            1: {"name": "ğŸ˜„ Ø´Ø§Ø¯", "color": (0, 255, 0), "count": 0},
            2: {"name": "ğŸ˜¢ ØºÙ…Ú¯ÛŒÙ†", "color": (255, 0, 0), "count": 0},
            3: {"name": "ğŸ˜² Ù…ØªØ¹Ø¬Ø¨", "color": (0, 255, 255), "count": 0},
            4: {"name": "ğŸ˜ Ø®Ù†Ø«ÛŒ", "color": (255, 255, 0), "count": 0}
        }
        
        # ØªÙ†Ø¸ÛŒÙ…Ø§Øª UI
        self.ui_scale = 1.0
        self.show_charts = True
        self.dark_mode = True
        self.current_view = "main"  # main, stats, training
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§
        self.setup_folders()
    
    def setup_folders(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù¾ÙˆØ´Ù‡â€ŒÙ‡Ø§ÛŒ Ù„Ø§Ø²Ù…"""
        folders = ['sessions', 'exports', 'screenshots']
        for folder in folders:
            if not os.path.exists(folder):
                os.makedirs(folder)
    
    def create_chart_image(self):
        """Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¢Ù…Ø§Ø± Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        try:
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ Ø¢Ù…Ø§Ø±
            emotion_counts = {emotion: 0 for emotion in self.emotions}
            for emotion_id in self.emotion_history[-50:]:  # Ø¢Ø®Ø±ÛŒÙ† ÛµÛ° ØªØ´Ø®ÛŒØµ
                if emotion_id in emotion_counts:
                    emotion_counts[emotion_id] += 1
            
            # Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))
            
            # Ù†Ù…ÙˆØ¯Ø§Ø± Ù…ÛŒÙ„Ù‡â€ŒØ§ÛŒ
            emotions_list = [self.emotions[i]["name"] for i in range(5)]
            counts = [emotion_counts[i] for i in range(5)]
            colors = [self.emotions[i]["color"] for i in range(5)]
            
            # ØªØ¨Ø¯ÛŒÙ„ BGR Ø¨Ù‡ RGB Ø¨Ø±Ø§ÛŒ matplotlib
            colors_rgb = [(c[2]/255, c[1]/255, c[0]/255) for c in colors]
            
            bars = ax1.bar(emotions_list, counts, color=colors_rgb, alpha=0.7)
            ax1.set_title('ØªÙˆØ²ÛŒØ¹ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ø¢Ø®Ø±ÛŒÙ† ÛµÛ° ØªØ´Ø®ÛŒØµ)')
            ax1.tick_params(axis='x', rotation=45)
            
            # Ù†Ù…ÙˆØ¯Ø§Ø± Ø¯Ø§ÛŒØ±Ù‡â€ŒØ§ÛŒ
            total = sum(counts)
            if total > 0:
                ax2.pie(counts, labels=emotions_list, colors=colors_rgb, autopct='%1.1f%%')
                ax2.set_title('Ø¯Ø±ØµØ¯ Ø§Ø­Ø³Ø§Ø³Ø§Øª')
            
            plt.tight_layout()
            
            # ØªØ¨Ø¯ÛŒÙ„ Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ù‡ ØªØµÙˆÛŒØ± OpenCV
            canvas = FigureCanvasAgg(fig)
            canvas.draw()
            chart_image = np.frombuffer(canvas.tostring_rgb(), dtype=np.uint8)
            chart_image = chart_image.reshape(canvas.get_width_height()[::-1] + (3,))
            chart_image = cv2.cvtColor(chart_image, cv2.COLOR_RGB2BGR)
            
            plt.close(fig)
            return chart_image
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§ÛŒØ¬Ø§Ø¯ Ù†Ù…ÙˆØ¯Ø§Ø±: {e}")
            return None
    
    def draw_modern_ui(self, frame, faces, current_emotion=None, confidence=0.0):
        """Ø±Ø³Ù… Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù…Ø¯Ø±Ù†"""
        height, width = frame.shape[:2]
        
        # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡ Ù†ÛŒÙ…Ù‡ Ø´ÙØ§Ù Ø¨Ø±Ø§ÛŒ Ø§Ø·Ù„Ø§Ø¹Ø§Øª
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (width, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)
        
        # Ù‡Ø¯Ø±
        header_text = "ğŸ¤– Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª"
        cv2.putText(frame, header_text, (20, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)
        
        # Ø¢Ù…Ø§Ø± Ù„Ø­Ø¸Ù‡â€ŒØ§ÛŒ
        runtime = int(time.time() - self.session_start_time)
        stats_text = f"â±ï¸ {runtime}s | ğŸ‘¥ {self.faces_detected} | ğŸ¯ {self.predictions_made}"
        cv2.putText(frame, stats_text, (20, 60), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # ÙˆØ¶Ø¹ÛŒØª Ù…Ø¯Ù„
        model_status = "âœ… ML ÙØ¹Ø§Ù„" if self.is_trained else "âš ï¸ Ù…Ø¯Ù„ Ù¾Ø§ÛŒÙ‡"
        cv2.putText(frame, model_status, (20, 85), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0) if self.is_trained else (0, 165, 255), 1)
        
        # Ù†Ù…Ø§ÛŒØ´ Ø§Ø­Ø³Ø§Ø³ ÙØ¹Ù„ÛŒ
        if current_emotion is not None and len(faces) > 0:
            emotion_data = self.emotions[current_emotion]
            emotion_display = f"{emotion_data['name']} | Ø§Ø·Ù…ÛŒÙ†Ø§Ù†: {confidence:.0%}"
            cv2.putText(frame, emotion_display, (width - 400, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, emotion_data["color"], 2)
        
        # Ù†ÙˆØ§Ø± ÙˆØ¶Ø¹ÛŒØª Ù¾Ø§ÛŒÛŒÙ†
        cv2.rectangle(frame, (0, height-40), (width, height), (0, 0, 0), -1)
        
        # Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§
        help_items = [
            "F1: Ø§ØµÙ„ÛŒ", "F2: Ø¢Ù…Ø§Ø±", "F3: Ø¢Ù…ÙˆØ²Ø´", 
            "S: Ø¹Ú©Ø³", "C: Ù†Ù…ÙˆØ¯Ø§Ø±", "Q: Ø®Ø±ÙˆØ¬"
        ]
        
        x_pos = 20
        for item in help_items:
            cv2.putText(frame, item, (x_pos, height-15), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            x_pos += 120
    
    def draw_stats_view(self, frame):
        """Ù†Ù…Ø§ÛŒØ´ Ù†Ù…Ø§ÛŒ Ø¢Ù…Ø§Ø±"""
        height, width = frame.shape[:2]
        
        # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        frame.fill(50)  # Ø®Ø§Ú©Ø³ØªØ±ÛŒ ØªÛŒØ±Ù‡
        
        # Ø¹Ù†ÙˆØ§Ù†
        title = "ğŸ“Š Ø¢Ù…Ø§Ø± Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§"
        cv2.putText(frame, title, (width//2 - 150, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        # Ø§ÛŒØ¬Ø§Ø¯ Ùˆ Ù†Ù…Ø§ÛŒØ´ Ù†Ù…ÙˆØ¯Ø§Ø±
        chart = self.create_chart_image()
        if chart is not None:
            # ØªØºÛŒÛŒØ± Ø³Ø§ÛŒØ² Ù†Ù…ÙˆØ¯Ø§Ø± Ø¨Ø±Ø§ÛŒ Ù†Ù…Ø§ÛŒØ´
            chart_resized = cv2.resize(chart, (width-100, height-150))
            y_offset = 80
            frame[y_offset:y_offset+chart_resized.shape[0], 
                  50:50+chart_resized.shape[1]] = chart_resized
        
        # Ø¢Ù…Ø§Ø± Ú©Ù„ÛŒ
        stats_y = height - 60
        total_detections = len(self.emotion_history)
        if total_detections > 0:
            dominant_emotion = max(set(self.emotion_history), key=self.emotion_history.count)
            dominant_name = self.emotions[dominant_emotion]["name"]
            stats_text = f"ğŸ” Ú©Ù„ ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§: {total_detections} | ğŸ† Ø§Ø­Ø³Ø§Ø³ ØºØ§Ù„Ø¨: {dominant_name}"
            cv2.putText(frame, stats_text, (50, stats_y), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
    
    def draw_training_view(self, frame):
        """Ù†Ù…Ø§ÛŒØ´ Ù†Ù…Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´"""
        height, width = frame.shape[:2]
        
        # Ù¾Ø³â€ŒØ²Ù…ÛŒÙ†Ù‡
        frame.fill(60)
        
        # Ø¹Ù†ÙˆØ§Ù†
        title = "ğŸ“ Ø¨Ø®Ø´ Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„"
        cv2.putText(frame, title, (width//2 - 120, 50), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 2)
        
        # Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø¢Ù…ÙˆØ²Ø´
        training_info = [
            f"ğŸ“Š Ù†Ù…ÙˆÙ†Ù‡â€ŒÙ‡Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´ÛŒ: {len(self.training_data)}",
            f"ğŸ¤– ÙˆØ¶Ø¹ÛŒØª Ù…Ø¯Ù„: {'Ø¢Ù…ÙˆØ²Ø´ Ø¯ÛŒØ¯Ù‡' if self.is_trained else 'Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¢Ù…ÙˆØ²Ø´'}",
            f"ğŸ¯ Ø­Ø¯Ø§Ù‚Ù„ Ù†Ù…ÙˆÙ†Ù‡ Ø¨Ø±Ø§ÛŒ Ø¢Ù…ÙˆØ²Ø´: Û±Û° Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø² Ù‡Ø± Ø§Ø­Ø³Ø§Ø³"
        ]
        
        y_pos = 100
        for info in training_info:
            cv2.putText(frame, info, (100, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            y_pos += 30
        
        # Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ
        y_pos += 20
        cv2.putText(frame, "ğŸ¯ Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª:", (100, y_pos), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 1)
        y_pos += 25
        
        emotion_guides = [
            "0: ğŸ˜  Ø¹ØµØ¨Ø§Ù†ÛŒ", "1: ğŸ˜„ Ø´Ø§Ø¯", "2: ğŸ˜¢ ØºÙ…Ú¯ÛŒÙ†", 
            "3: ğŸ˜² Ù…ØªØ¹Ø¬Ø¨", "4: ğŸ˜ Ø®Ù†Ø«ÛŒ"
        ]
        
        x_pos = 100
        for guide in emotion_guides:
            cv2.putText(frame, guide, (x_pos, y_pos), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1)
            x_pos += 150
        
        # Ø¯Ú©Ù…Ù‡â€ŒÙ‡Ø§ÛŒ Ù…Ø¬Ø§Ø²ÛŒ
        y_pos += 50
        buttons = [
            ("T: Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„", (100, y_pos)),
            ("L: Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ù…Ø¯Ù„", (250, y_pos)),
            ("S: Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡", (400, y_pos))
        ]
        
        for text, pos in buttons:
            cv2.rectangle(frame, (pos[0]-10, pos[1]-20), (pos[0]+120, pos[1]+5), (100, 100, 100), -1)
            cv2.putText(frame, text, pos, 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
    
    def save_screenshot(self, frame):
        """Ø°Ø®ÛŒØ±Ù‡ Ø¹Ú©Ø³ Ø§Ø² ØµÙØ­Ù‡"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"screenshots/screenshot_{timestamp}.jpg"
        cv2.imwrite(filename, frame)
        print(f"ğŸ“¸ Ø¹Ú©Ø³ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
    
    def export_session_data(self):
        """Ø®Ø±ÙˆØ¬ÛŒ Ú¯Ø±ÙØªÙ† Ø§Ø² Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù„Ø³Ù‡"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"exports/session_{timestamp}.json"
        
        session_data = {
            "session_date": datetime.now().isoformat(),
            "duration": int(time.time() - self.session_start_time),
            "total_faces": self.faces_detected,
            "total_predictions": self.predictions_made,
            "emotion_distribution": {self.emotions[i]["name"]: self.emotions[i]["count"] for i in range(5)},
            "emotion_history": self.emotion_history
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(session_data, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§ÛŒ Ø¬Ù„Ø³Ù‡ Ø°Ø®ÛŒØ±Ù‡ Ø´Ø¯: {filename}")
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø§Ø¯Ù‡â€ŒÙ‡Ø§: {e}")
    
    def predict_emotion_basic(self, face_roi):
        """Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª (Ø±ÙˆØ´ Ù¾Ø§ÛŒÙ‡)"""
        try:
            gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
            brightness = np.mean(gray)
            
            if brightness > 170:
                return 1, 0.8  # Ø´Ø§Ø¯
            elif brightness < 100:
                return 2, 0.7  # ØºÙ…Ú¯ÛŒÙ†
            elif brightness > 200:
                return 3, 0.75  # Ù…ØªØ¹Ø¬Ø¨
            else:
                return 4, 0.6  # Ø®Ù†Ø«ÛŒ
        except:
            return 4, 0.5
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ"""
        if self.face_cascade.empty() or not self.cap.isOpened():
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…")
            return
        
        print("ğŸ¨ Ø³ÛŒØ³ØªÙ… ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ø¨Ø§ Ø±Ø§Ø¨Ø· Ú©Ø§Ø±Ø¨Ø±ÛŒ Ù¾ÛŒØ´Ø±ÙØªÙ‡")
        print("=" * 60)
        print("âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")
        print("\nğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ Ú©Ù„ÛŒØ¯Ù‡Ø§:")
        print("F1: Ù†Ù…Ø§ÛŒ Ø§ØµÙ„ÛŒ | F2: Ø¢Ù…Ø§Ø± | F3: Ø¢Ù…ÙˆØ²Ø´")
        print("S: Ø¹Ú©Ø³ Ø§Ø² ØµÙØ­Ù‡ | E: Ø®Ø±ÙˆØ¬ÛŒ Ø¯Ø§Ø¯Ù‡ | Q: Ø®Ø±ÙˆØ¬")
        print("0-4: Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ Ø§Ø­Ø³Ø§Ø³Ø§Øª")
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡ (ÙÙ‚Ø· Ø¯Ø± Ù†Ù…Ø§ÛŒ Ø§ØµÙ„ÛŒ)
            faces = []
            current_emotion = None
            confidence = 0.0
            
            if self.current_view == "main":
                gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
                faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(100, 100))
                
                if len(faces) > 0:
                    self.faces_detected += len(faces)
                    
                    for (x, y, w, h) in faces:
                        face_roi = frame[y:y+h, x:x+w]
                        emotion_id, conf = self.predict_emotion_basic(face_roi)
                        current_emotion = emotion_id
                        confidence = conf
                        
                        # Ø¨Ù‡ Ø±ÙˆØ²Ø±Ø³Ø§Ù†ÛŒ Ø¢Ù…Ø§Ø±
                        self.emotions[emotion_id]["count"] += 1
                        self.emotion_history.append(emotion_id)
                        self.predictions_made += 1
                        
                        # Ø±Ø³Ù… Ù…Ø³ØªØ·ÛŒÙ„ Ø¯ÙˆØ± Ú†Ù‡Ø±Ù‡
                        emotion_data = self.emotions[emotion_id]
                        cv2.rectangle(frame, (x, y), (x+w, y+h), emotion_data["color"], 3)
                        
                        # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Ù‡Ø±Ù‡
                        emotion_text = f"{emotion_data['name']}"
                        cv2.putText(frame, emotion_text, (x, y-10), 
                                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, emotion_data["color"], 2)
            
            # Ø±Ø³Ù… UI Ø¨Ø± Ø§Ø³Ø§Ø³ Ù†Ù…Ø§ÛŒ ÙØ¹Ù„ÛŒ
            if self.current_view == "main":
                self.draw_modern_ui(frame, faces, current_emotion, confidence)
            elif self.current_view == "stats":
                self.draw_stats_view(frame)
            elif self.current_view == "training":
                self.draw_training_view(frame)
            
            # Ù†Ù…Ø§ÛŒØ´ Ù¾Ù†Ø¬Ø±Ù‡
            window_title = "ğŸ­ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª - "
            if self.current_view == "main":
                window_title += "Ù†Ù…Ø§ÛŒ Ø§ØµÙ„ÛŒ"
            elif self.current_view == "stats":
                window_title += "Ø¢Ù…Ø§Ø± Ùˆ Ù†Ù…ÙˆØ¯Ø§Ø±Ù‡Ø§"
            elif self.current_view == "training":
                window_title += "Ø¢Ù…ÙˆØ²Ø´ Ù…Ø¯Ù„"
            
            cv2.imshow(window_title, frame)
            
            # Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒØ¯Ù‡Ø§
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == ord('Q'):
                break
            elif key == 0:  # F1
                self.current_view = "main"
            elif key == 0:  # F2
                self.current_view = "stats"
            elif key == 0:  # F3
                self.current_view = "training"
            elif key == ord('s') or key == ord('S'):
                self.save_screenshot(frame)
            elif key == ord('e') or key == ord('E'):
                self.export_session_data()
            elif ord('0') <= key <= ord('4'):
                emotion_id = key - ord('0')
                emotion_name = self.emotions[emotion_id]["name"]
                print(f"ğŸ·ï¸  Ø­Ø§Ù„Øª Ø¨Ø±Ú†Ø³Ø¨â€ŒÚ¯Ø°Ø§Ø±ÛŒ: {emotion_name}")
        
        # Ù¾Ø§ÛŒØ§Ù† Ø¨Ø±Ù†Ø§Ù…Ù‡
        self.cap.release()
        cv2.destroyAllWindows()
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
        runtime = int(time.time() - self.session_start_time)
        print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ Ø¬Ù„Ø³Ù‡:")
        print(f"â±ï¸  Ù…Ø¯Øª Ø²Ù…Ø§Ù†: {runtime} Ø«Ø§Ù†ÛŒÙ‡")
        print(f"ğŸ‘¥ Ú†Ù‡Ø±Ù‡â€ŒÙ‡Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡: {self.faces_detected}")
        print(f"ğŸ¯ Ù¾ÛŒØ´â€ŒØ¨ÛŒÙ†ÛŒâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡: {self.predictions_made}")
        
        if self.emotion_history:
            dominant = max(set(self.emotion_history), key=self.emotion_history.count)
            print(f"ğŸ† Ø§Ø­Ø³Ø§Ø³ ØºØ§Ù„Ø¨: {self.emotions[dominant]['name']}")

if __name__ == "__main__":
    ui_system = AdvancedEmotionUI()
    ui_system.run()
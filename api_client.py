import requests
import base64
import json
import cv2

class EmotionAPIClient:
    def __init__(self, base_url="http://localhost:5000"):
        self.base_url = base_url
    
    def image_to_base64(self, image_path):
        """ØªØ¨Ø¯ÛŒÙ„ ØªØµÙˆÛŒØ± Ø¨Ù‡ base64"""
        try:
            with open(image_path, "rb") as image_file:
                encoded_string = base64.b64encode(image_file.read()).decode('utf-8')
            return f"data:image/jpeg;base64,{encoded_string}"
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø®ÙˆØ§Ù†Ø¯Ù† ØªØµÙˆÛŒØ±: {e}")
            return None
    
    def analyze_image(self, image_path):
        """Ø§Ø±Ø³Ø§Ù„ ØªØµÙˆÛŒØ± Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ø§Ù„ÛŒØ²"""
        image_data = self.image_to_base64(image_path)
        if not image_data:
            return None
        
        try:
            response = requests.post(
                f"{self.base_url}/analyze",
                json={"image": image_data},
                timeout=30
            )
            
            if response.status_code == 200:
                return response.json()
            else:
                print(f"âŒ Ø®Ø·Ø§ÛŒ Ø³Ø±ÙˆØ±: {response.status_code}")
                return None
                
        except requests.exceptions.RequestException as e:
            print(f"âŒ Ø®Ø·Ø§ Ø¯Ø± Ø§Ø±ØªØ¨Ø§Ø· Ø¨Ø§ Ø³Ø±ÙˆØ±: {e}")
            return None
    
    def get_stats(self):
        """Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆØ±"""
        try:
            response = requests.get(f"{self.base_url}/stats")
            if response.status_code == 200:
                return response.json()
            else:
                return None
        except:
            return None
    
    def test_webcam(self):
        """ØªØ³Øª Ø¨Ø§ ÙˆØ¨Ú©Ù…"""
        cap = cv2.VideoCapture(0)
        print("ğŸ¥ ÙˆØ¨Ú©Ù… ÙØ¹Ø§Ù„ Ø´Ø¯. Ø¨Ø±Ø§ÛŒ Ø®Ø±ÙˆØ¬ 'q' Ø¨Ø²Ù†ÛŒØ¯.")
        
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            # ØªØ¨Ø¯ÛŒÙ„ ÙØ±ÛŒÙ… Ø¨Ù‡ base64
            _, buffer = cv2.imencode('.jpg', frame)
            image_data = base64.b64encode(buffer).decode('utf-8')
            image_data = f"data:image/jpeg;base64,{image_data}"
            
            # Ø§Ø±Ø³Ø§Ù„ Ø¨Ø±Ø§ÛŒ Ø¢Ù†Ø§Ù„ÛŒØ²
            try:
                response = requests.post(
                    f"{self.base_url}/analyze",
                    json={"image": image_data},
                    timeout=5
                )
                
                if response.status_code == 200:
                    result = response.json()
                    if result["success"] and result["faces_detected"] > 0:
                        for face in result["analysis"]:
                            x = face["bounding_box"]["x"]
                            y = face["bounding_box"]["y"]
                            w = face["bounding_box"]["width"]
                            h = face["bounding_box"]["height"]
                            
                            # Ø±Ø³Ù… Ù…Ø³ØªØ·ÛŒÙ„
                            color = tuple(face["color"])
                            cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)
                            
                            # Ù†Ù…Ø§ÛŒØ´ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                            text = f"{face['emoji']} {face['emotion']} ({face['confidence']:.0%})"
                            cv2.putText(frame, text, (x, y-10), 
                                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
                
                cv2.imshow('Emotion API Test - Press Q to quit', frame)
                
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
                    
            except requests.exceptions.RequestException:
                cv2.imshow('Emotion API Test - Press Q to quit', frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
        
        cap.release()
        cv2.destroyAllWindows()

if __name__ == "__main__":
    client = EmotionAPIClient()
    
    print("ğŸ¤– Ú©Ù„Ø§ÛŒÙ†Øª API ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª")
    print("1. Ø¢Ù†Ø§Ù„ÛŒØ² ØªØµÙˆÛŒØ± Ø§Ø² ÙØ§ÛŒÙ„")
    print("2. ØªØ³Øª Ø¨Ø§ ÙˆØ¨Ú©Ù…")
    print("3. Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆØ±")
    
    choice = input("Ø§Ù†ØªØ®Ø§Ø¨ Ú©Ù†ÛŒØ¯ (1/2/3): ").strip()
    
    if choice == "1":
        image_path = input("Ù…Ø³ÛŒØ± ØªØµÙˆÛŒØ± Ø±Ø§ ÙˆØ§Ø±Ø¯ Ú©Ù†ÛŒØ¯: ").strip()
        result = client.analyze_image(image_path)
        if result:
            print("âœ… Ù†ØªÛŒØ¬Ù‡ Ø¢Ù†Ø§Ù„ÛŒØ²:")
            print(json.dumps(result, ensure_ascii=False, indent=2))
        else:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¢Ù†Ø§Ù„ÛŒØ² ØªØµÙˆÛŒØ±")
    
    elif choice == "2":
        client.test_webcam()
    
    elif choice == "3":
        stats = client.get_stats()
        if stats:
            print("ğŸ“Š Ø¢Ù…Ø§Ø± Ø³Ø±ÙˆØ±:")
            print(json.dumps(stats, ensure_ascii=False, indent=2))
        else:
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø±ÛŒØ§ÙØª Ø¢Ù…Ø§Ø±")
    
    else:
        print("âŒ Ø§Ù†ØªØ®Ø§Ø¨ Ù†Ø§Ù…Ø¹ØªØ¨Ø±")
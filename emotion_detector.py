import cv2
import numpy as np
import os
import time

class EmotionDetector:
    def __init__(self):
        self.face_cascade = cv2.CascadeClassifier("haarcascade_frontalface_default.xml")
        self.cap = cv2.VideoCapture(0)
        self.emotions = {
            0: {"name": "ğŸ˜  Ø¹ØµØ¨Ø§Ù†ÛŒ", "color": (0, 0, 255)},
            1: {"name": "ğŸ˜„ Ø´Ø§Ø¯", "color": (0, 255, 0)},
            2: {"name": "ğŸ˜¢ ØºÙ…Ú¯ÛŒÙ†", "color": (255, 0, 0)},
            3: {"name": "ğŸ˜² Ù…ØªØ¹Ø¬Ø¨", "color": (0, 255, 255)},
            4: {"name": "ğŸ˜ Ø®Ù†Ø«ÛŒ", "color": (255, 255, 0)}
        }
    
    def analyze_face_features(self, face_roi):
        """Ø¢Ù†Ø§Ù„ÛŒØ² ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§ÛŒ Ú†Ù‡Ø±Ù‡ Ø¨Ø±Ø§ÛŒ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª"""
        try:
            # ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ Ø®Ø§Ú©Ø³ØªØ±ÛŒ
            gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
            height, width = gray.shape
            
            # ØªÙ‚Ø³ÛŒÙ… Ú†Ù‡Ø±Ù‡ Ø¨Ù‡ Ù†ÙˆØ§Ø­ÛŒ Ù…Ø®ØªÙ„Ù
            top_half = gray[0:height//2, :]      # Ù†Ø§Ø­ÛŒÙ‡ Ú†Ø´Ù…â€ŒÙ‡Ø§ Ùˆ Ø§Ø¨Ø±ÙˆÙ‡Ø§
            bottom_half = gray[height//2:, :]    # Ù†Ø§Ø­ÛŒÙ‡ Ø¯Ù‡Ø§Ù†
            
            # Ù…Ø­Ø§Ø³Ø¨Ù‡ ÙˆÛŒÚ˜Ú¯ÛŒâ€ŒÙ‡Ø§
            brightness = np.mean(gray)
            contrast = np.std(gray)
            top_bottom_ratio = np.mean(top_half) / max(np.mean(bottom_half), 1)
            
            # Ù…Ù†Ø·Ù‚ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª
            if brightness > 170 and contrast > 60:
                return 1, 0.85  # Ø´Ø§Ø¯ - ØµÙˆØ±Øª Ø±ÙˆØ´Ù† Ø¨Ø§ Ú©Ù†ØªØ±Ø§Ø³Øª Ø¨Ø§Ù„Ø§
            elif brightness < 100:
                return 2, 0.75  # ØºÙ…Ú¯ÛŒÙ† - ØµÙˆØ±Øª ØªØ§Ø±ÛŒÚ©
            elif top_bottom_ratio > 1.3:
                return 3, 0.80  # Ù…ØªØ¹Ø¬Ø¨ - Ù†Ø§Ø­ÛŒÙ‡ Ø¨Ø§Ù„Ø§ÛŒÛŒ ÙØ¹Ø§Ù„
            elif contrast < 40:
                return 4, 0.70  # Ø®Ù†Ø«ÛŒ - Ú©Ù†ØªØ±Ø§Ø³Øª Ù¾Ø§ÛŒÛŒÙ†
            else:
                return 0, 0.65  # Ø¹ØµØ¨Ø§Ù†ÛŒ - Ø­Ø§Ù„Øª Ù¾ÛŒØ´â€ŒÙØ±Ø¶
                
        except Exception as e:
            return 4, 0.5  # Ø­Ø§Ù„Øª Ø®Ø·Ø§
    
    def run(self):
        """Ø§Ø¬Ø±Ø§ÛŒ Ø¨Ø±Ù†Ø§Ù…Ù‡ Ø§ØµÙ„ÛŒ"""
        if self.face_cascade.empty() or not self.cap.isOpened():
            print("âŒ Ø®Ø·Ø§ Ø¯Ø± Ø±Ø§Ù‡â€ŒØ§Ù†Ø¯Ø§Ø²ÛŒ Ø³ÛŒØ³ØªÙ…")
            return
        
        print("ğŸ­ Ø³ÛŒØ³ØªÙ… Ù¾ÛŒØ´Ø±ÙØªÙ‡ ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª")
        print("=" * 45)
        print("âœ… Ø³ÛŒØ³ØªÙ… Ø¢Ù…Ø§Ø¯Ù‡ Ø§Ø³Øª")
        print("\nğŸ¯ Ø±Ø§Ù‡Ù†Ù…Ø§:")
        print("- ğŸ˜„ Ø´Ø§Ø¯: Ù„Ø¨Ø®Ù†Ø¯ Ø¨Ø²Ù†")
        print("- ğŸ˜¢ ØºÙ…Ú¯ÛŒÙ†: Ø§Ø®Ù… Ú©Ù†") 
        print("- ğŸ˜² Ù…ØªØ¹Ø¬Ø¨: Ú†Ø´Ù…â€ŒÙ‡Ø§ Ø±Ùˆ Ø¨Ø§Ø² Ú©Ù†")
        print("- ğŸ˜  Ø¹ØµØ¨Ø§Ù†ÛŒ: Ø§Ø¨Ø±ÙˆÙ‡Ø§ Ø±Ùˆ Ú¯Ø±Ù‡ Ø¨Ø²Ù†")
        print("- Q: Ø®Ø±ÙˆØ¬")
        
        start_time = time.time()
        detection_history = []
        
        while True:
            ret, frame = self.cap.read()
            if not ret:
                break
            
            # ØªØ´Ø®ÛŒØµ Ú†Ù‡Ø±Ù‡
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = self.face_cascade.detectMultiScale(gray, 1.1, 4, minSize=(100, 100))
            
            for (x, y, w, h) in faces:
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Ø§Ø­ÛŒÙ‡ Ú†Ù‡Ø±Ù‡
                face_roi = frame[y:y+h, x:x+w]
                
                # ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                emotion_id, confidence = self.analyze_face_features(face_roi)
                emotion_data = self.emotions[emotion_id]
                
                # Ø°Ø®ÛŒØ±Ù‡ Ø¯Ø± ØªØ§Ø±ÛŒØ®Ú†Ù‡
                detection_history.append(emotion_id)
                if len(detection_history) > 10:
                    detection_history.pop(0)
                
                # Ø±Ø³Ù… Ù…Ø³ØªØ·ÛŒÙ„ Ø¨Ø§ Ø±Ù†Ú¯ Ø§Ø­Ø³Ø§Ø³
                cv2.rectangle(frame, (x, y), (x+w, y+h), emotion_data["color"], 3)
                
                # Ù†Ù…Ø§ÛŒØ´ Ø§Ø­Ø³Ø§Ø³Ø§Øª
                emotion_text = f"{emotion_data['name']} ({confidence:.0%})"
                cv2.putText(frame, emotion_text, (x, y-10), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, emotion_data["color"], 2)
                
                # Ù†Ù…Ø§ÛŒØ´ Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ú†Ù‡Ø±Ù‡
                info_text = f"Size: {w}x{h}"
                cv2.putText(frame, info_text, (x, y+h+25), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, emotion_data["color"], 1)
            
            # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø±
            runtime = int(time.time() - start_time)
            stats_text = f"Ú†Ù‡Ø±Ù‡â€ŒÙ‡Ø§: {len(faces)} | Ø²Ù…Ø§Ù†: {runtime}s"
            cv2.putText(frame, stats_text, (10, 30), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            # Ù†Ù…Ø§ÛŒØ´ Ø§Ø­Ø³Ø§Ø³ ØºØ§Ù„Ø¨
            if detection_history:
                dominant_emotion = max(set(detection_history), key=detection_history.count)
                dominant_text = f"Ø§Ø­Ø³Ø§Ø³ ØºØ§Ù„Ø¨: {self.emotions[dominant_emotion]['name']}"
                cv2.putText(frame, dominant_text, (10, 60), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
            
            cv2.putText(frame, "Q: Ø®Ø±ÙˆØ¬", (10, frame.shape[0]-10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
            
            cv2.imshow("ØªØ´Ø®ÛŒØµ Ø§Ø­Ø³Ø§Ø³Ø§Øª Ú†Ù‡Ø±Ù‡ - Emotion Detection", frame)
            
            # Ù…Ø¯ÛŒØ±ÛŒØª Ú©Ù„ÛŒØ¯Ù‡Ø§
            key = cv2.waitKey(1) & 0xFF
            if key in [ord('q'), ord('Q'), 27]:
                break
        
        # ØªÙ…ÛŒØ² Ú©Ø±Ø¯Ù†
        self.cap.release()
        cv2.destroyAllWindows()
        
        # Ù†Ù…Ø§ÛŒØ´ Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ
        runtime = int(time.time() - start_time)
        print(f"\nğŸ“Š Ø¢Ù…Ø§Ø± Ù†Ù‡Ø§ÛŒÛŒ:")
        print(f"â±ï¸  Ù…Ø¯Øª Ø§Ø¬Ø±Ø§: {runtime} Ø«Ø§Ù†ÛŒÙ‡")
        print(f"ğŸ­ ØªØ´Ø®ÛŒØµâ€ŒÙ‡Ø§ÛŒ Ø§Ù†Ø¬Ø§Ù… Ø´Ø¯Ù‡: {len(detection_history)}")
        if detection_history:
            dominant = max(set(detection_history), key=detection_history.count)
            print(f"ğŸ† Ø§Ø­Ø³Ø§Ø³ ØºØ§Ù„Ø¨: {self.emotions[dominant]['name']}")

if __name__ == "__main__":
    detector = EmotionDetector()
    detector.run()